{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "os.environ['SPARK_HOME'] = os.getenv('SPARK_HOME')\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = 'jupyter'\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON_OPTS\"] = 'lab'\n",
    "os.environ['PYSPARK_PYTHON'] = \"python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master('local[*]').appName('Mediacal_cost_prediction').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+--------+------+---------+-----------+\n",
      "|age|   sex|   bmi|children|smoker|   region|    charges|\n",
      "+---+------+------+--------+------+---------+-----------+\n",
      "| 19|female|  27.9|       0|   yes|southwest|  16884.924|\n",
      "| 18|  male| 33.77|       1|    no|southeast|  1725.5523|\n",
      "| 28|  male|  33.0|       3|    no|southeast|   4449.462|\n",
      "| 33|  male|22.705|       0|    no|northwest|21984.47061|\n",
      "| 32|  male| 28.88|       0|    no|northwest|  3866.8552|\n",
      "| 31|female| 25.74|       0|    no|southeast|  3756.6216|\n",
      "| 46|female| 33.44|       1|    no|southeast|  8240.5896|\n",
      "| 37|female| 27.74|       3|    no|northwest|  7281.5056|\n",
      "| 37|  male| 29.83|       2|    no|northeast|  6406.4107|\n",
      "| 60|female| 25.84|       0|    no|northwest|28923.13692|\n",
      "| 25|  male| 26.22|       0|    no|northeast|  2721.3208|\n",
      "| 62|female| 26.29|       0|   yes|southeast| 27808.7251|\n",
      "| 23|  male|  34.4|       0|    no|southwest|   1826.843|\n",
      "| 56|female| 39.82|       0|    no|southeast| 11090.7178|\n",
      "| 27|  male| 42.13|       0|   yes|southeast| 39611.7577|\n",
      "| 19|  male|  24.6|       1|    no|southwest|   1837.237|\n",
      "| 52|female| 30.78|       1|    no|northeast| 10797.3362|\n",
      "| 23|  male|23.845|       0|    no|northeast| 2395.17155|\n",
      "| 56|  male|  40.3|       0|    no|southwest|  10602.385|\n",
      "| 30|  male|  35.3|       0|   yes|southwest|  36837.467|\n",
      "+---+------+------+--------+------+---------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('./data/medical.csv', header=True, inferSchema=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = df.columns\n",
    "categorical_cols.remove('age')\n",
    "categorical_cols.remove('bmi')\n",
    "categorical_cols.remove('children')\n",
    "categorical_cols.remove('charges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "string_indexer = StringIndexer(inputCols=categorical_cols,\n",
    "                               outputCols=['sex_index', 'smoker_index', 'region_index'])\n",
    "\n",
    "string_indexer = string_indexer.fit(df)\n",
    "\n",
    "df = string_indexer.transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df = df.withColumn('sex_index', col('sex_index').cast('int'))\n",
    "df = df.withColumn('smoker_index', col('smoker_index').cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(inputCol='region_index',\n",
    "                        outputCol='region_one_hot')\n",
    "\n",
    "encoder = encoder.fit(df)\n",
    "df = encoder.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=['age', 'bmi', 'children'], \n",
    "                            outputCol='numerical_cols_vector')\n",
    "\n",
    "df = assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "scaler = StandardScaler(inputCol='numerical_cols_vector',\n",
    "                        outputCol='scaled_numerical_cols_vector',\n",
    "                        withStd=True, withMean=True)\n",
    "\n",
    "scaler = scaler.fit(df)\n",
    "\n",
    "df = scaler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=['sex_index', 'smoker_index', 'region_one_hot', 'scaled_numerical_cols_vector'],\n",
    "                            outputCol='final_features_vector')\n",
    "\n",
    "df = assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(final_features_vector=DenseVector([1.0, 1.0, 0.0, 0.0, 1.0, -1.4382, -0.4532, -0.9083])),\n",
       " Row(final_features_vector=SparseVector(8, {2: 1.0, 5: -1.5094, 6: 0.5094, 7: -0.0787})),\n",
       " Row(final_features_vector=SparseVector(8, {2: 1.0, 5: -0.7977, 6: 0.3832, 7: 1.5803})),\n",
       " Row(final_features_vector=SparseVector(8, {3: 1.0, 5: -0.4418, 6: -1.305, 7: -0.9083})),\n",
       " Row(final_features_vector=SparseVector(8, {3: 1.0, 5: -0.513, 6: -0.2924, 7: -0.9083})),\n",
       " Row(final_features_vector=DenseVector([1.0, 0.0, 1.0, 0.0, 0.0, -0.5841, -0.8074, -0.9083])),\n",
       " Row(final_features_vector=DenseVector([1.0, 0.0, 1.0, 0.0, 0.0, 0.4835, 0.4553, -0.0787])),\n",
       " Row(final_features_vector=DenseVector([1.0, 0.0, 0.0, 1.0, 0.0, -0.1571, -0.4794, 1.5803])),\n",
       " Row(final_features_vector=SparseVector(8, {5: -0.1571, 6: -0.1367, 7: 0.7508})),\n",
       " Row(final_features_vector=DenseVector([1.0, 0.0, 0.0, 1.0, 0.0, 1.4799, -0.791, -0.9083]))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('final_features_vector').take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
